\documentclass{trlnotes}
\usepackage{trmath}
\addcompatiblelayout{commonplace}
\setlayout{commonplace}
\usepackage{trthm}
\usepackage{trsym} 
\usepackage{trphys}
% \input{mdefs}
\usepackage{silence}
\WarningFilter{latex}{Reference}
\graphicspath{{../../img/}}
\newtagform{roman}[\renewcommand{\theequation}{\Roman{equation}}]()
\begin{document}
\paragraph{Краевая задача для ОДУ 2 порядка и сведение к задаче Коши}
\label{par:ode::bprobl}
\begin{defn}\label{defn:ode::bprobl}
  Рассмотрим ОДУ 2 порядка
  \[
    y'' + p(x) y' + q(x) y = f(x) \qquad y \in C^2([a;b])
  \]
  и 3 варианта условий на $y$
  \begin{enumerate}[I]
    \item $y(a) = A, \quad y(b) = B$ \label{it:ode::bprobl::cond:i}
    \item $y'(a) = A, \quad y'(b) = B$ \label{it:ode::bprobl::cond::ii}
    \item $y'(a) = α y(a) + A, \quad y'(b) = βy(b) + B$ \label{it:ode::bprobl::cond::iii}
    \end{enumerate}
  
  Если $y$~--- решение для которого выполнено какое-то из условий выше, то $y$~--- решение
  граничной задачи.
\end{defn}

\begin{defn}[Однородная краевая задача]\label{defn:ode::bprobl::hom}
  Положим $f \equiv 0$ в \ref{defn:ode::bprobl}.
\end{defn}
\begin{defn}[Однородные граничные условия]\label{defn:ode::bprobl::hombnd}
  Положим $A = B = 0$ в граничных условиях в \ref{defn:ode::bprobl}
\end{defn}

\begin{thrm}[об альтернативе]\label{thrm:ode::bprobl::alt}
  Рассмотрим однородную граничную задачу с однородными граничными условиями.
  Пусть $y_H$~--- решение однородной задачи. 

  Тогда
  \begin{enumerate}
    \item $y_0 \equiv 0$~--- единственное решение однородной задачи \so неоднородная краевая 
      задача имеет единственное решение
    \item $y_0 \equiv 0$~--- неединственное решение однородной задачи \so неоднородная краевая 
      задача имеет бесконечно много или не имеет решений вовсе
  \end{enumerate}
\end{thrm}


\begin{prf}
  Рассмотреть решение неоднородной краевой в виде $y(x) = y_0(x) + c_1 y_1(x) + c_2 y_2(x)$
  и подставить граничные условия, а дальше все следует из линейной алгебры.
\end{prf}


Разберёмся как численно найти $y_0, y_1, y_2$, потребовавшиеся в предыдущем доказательстве.
Будем считать что $p,q,f$ определены на $I \ni [a;b]$, так что $y$ можно продолжить 
на $(a-ε;b+ε)$. 
\begin{enumerate}
  \item $y(a) = 0$, $y'(a) = 0$. Поскольку $0$ явно решение однородной задачи, то что мы
    найдем будет как раз частным решением неоднородной задачи (Коши!).
  \item $y_H(a) = 1$, $y'_H(a) = 0$ и решаем мы тут однородную задачу (Коши!). Будем считать то что
    нашлось $y_1$
  \item $y_H(a) = 0$, $y'_H(a) = 1$. Скажем что это $y_2$. Здесь важно заметить про линейную
    независимость $y_1$ и $y_2$. Найдем определитель Вронского в точке $a$
    \[
      W = \begin{vmatrix}
        y_1(a) & y_2(a) \\
        y_1'(a) & y_2'(a) 
      \end{vmatrix} = 
      \begin{vmatrix}
        1 & 0 \\ 
        0 & 1 \\
      \end{vmatrix} = 1 \neq 0
    \]
    А тогда он нигде не ноль. А значит $y_1$ и $y_2$ линейно независимы.
\end{enumerate}

Всё это называется \emph{методом начальных данных} для решения краевой задачи.

В рассуждении выше можно было бы взять другие начальные данные дабы
упростить себе жизнь. Ведь никто не запрещает запихать, например, кусок $y_2$ в $y_0$
(если мы уже знаем правильное $c_2$). Нам просто были нужны какие-то линейно независимые
решения однородной задачи.

Рассмотрим граничную задачу в форме \ref{it:ode::bprobl::cond::iii}
\begin{enumerate}
  \item $y(a) = 0$, $y'(a) = A$, нашли  $y_0$.
  \item $y_H(a) = 1$, $y'_H(a) = α$, нашли $y_1$.
  \item $y_H(a) = 0$, $y'_H(a) = 0$. Мы просто решили что $y_2 \equiv 0$. Эту ЗК мы даже
    не решаем, а сразу знаем ответ.
\end{enumerate}
При таком раскладе $y(x) = y_0(x) + c_1 y_1(x)$. 
Проверим левое граничное условие 
\[
  \begin{split}
    y(a) &= y_0(a) + c_1\, y_1(a) = 0 + c_1 \, 1 = c_1 \\
    y'(a) &= y_0'(a) + c_1\, y_1'(a) = A + c_1 \, α = A + α\ y(a)
  \end{split}
\]
Как видно, всё получилось.

В случае \ref{it:ode::bprobl::cond:i} можно сделать так:
\begin{enumerate}
  \item $y(a) = A$, $y'(a) = 0$, нашли $y_0$.
  \item $y_H(a) = 0$, $y_H'(a) = 1$, нашли $y_1$.
\end{enumerate}
Как видно, свободы в выборе $c_1$ хватает чтобы разобраться с правой границей.

\begin{exmp}
  $y'' - q^2 y =0$, $y(0) = 1$, $y(b) = 1$

  \underdev, а он важный вообще-то, из него необходимость метода прогонки следует.
\end{exmp}

\paragraph{Метод дифференциальной прогонки}
\label{par:ode::difftdma}

Здесь будем решать краевую задачу с граничными условиями в форме \ref{it:ode::bprobl::cond::iii}.

Рассмотрим $α(x)$, $β(x) \that$ (прогоночные коэффициенты)
\begin{equation} \label{eq:ode::difftdma::tmda}
  y'(x) = α(x) \, y(x) + β(x)
\end{equation}
Такая форма напрашивается при вспоминании трюка, который мы делали в прошлом параграфе.
Там как раз $y'(a) = y_0(a) + c_1\, y_1(a)$, а $c_1 = y(a)$.
Здесь мы пока вводим прогоночные коэффициенты формально, а существование покажем конструктивно.

Найдем уравнения на $α, β$
\[
  \begin{aligned}
    y'  &= α y + β \\
    y'' &= α y' + α'y + β'
  \end{aligned} \so
  \begin{aligned}[t]
    &y'' + py' + qy = f \\
    \iff &αy' + α'y + β' + p (αy + β) + qy = f \\
    \iff &y\,(\underbrace{α^2 + α' + p α + q}_{0}) + \underbrace{α β + β' + pβ}_f = f 
  \end{aligned}
\]
В итоге получаем систему ОДУ первого порядка
\begin{equation}\label{eq:ode::difftdma::direct}
  \begin{aligned}
    α' &= - α^2 - p α - q \\
    β' &= f - pβ - αβ \\
  \end{aligned}
\end{equation}

Посмотрим что происходит на правом конце\footnote{а что делать если $α(b)=β$ неясно}
\[
  \begin{aligned}
    y'(b) &= α(b) y(b) + β(b) \\
    y'(b) &= β y(b) + B \\
  \end{aligned} \so y(b) = \frac{B- β(b)}{α(b) - β} 
\]
Сам метод выглядит так:
\begin{description}
  \item[прямая прогонка:] решаем систему \eqref{eq:ode::difftdma::direct} с начальными данными
    $α(a) = α$, $β(a) = A$.
  \item[обратная прогонка:] уже зная $α(x)$, $β(x)$ решаем \eqref{eq:ode::difftdma::tmda} c
    начальными данными $y(b) = \frac{B- β(b)}{α(b) - β}$.
\end{description}

\begin{rem}
  Рассмотрим однородную задачу с однородными граничными условиями. 
  Тогда \eqref{eq:ode::difftdma::tmda} переходит в $y'(x) = α(x) \, y(x)$.
  Если при этом $\exists\, c\in (a;b) \that y(c) = 0 \land y'(c) \neq 0$, то $α(c)$ не
  существует. Так что, как видно, не всякое решение краевой задачи можно найти методом
  прогонки.
\end{rem}

\paragraph{Метод прогонки для систем ОДУ}
\label{par:ode::tdmasys}

\begin{defn}\label{defn:ode::tdmasys::bprobl}
  Рассмотрим ОДУ
  \begin{equation}\label{eq:ode::tdmasys::ode}
    \v y' = \hat A(x) \,\v y + \v f(x) \qquad \v y \in C^2([a;b]), \quad y \colon [a;b]\to \R^s
  \end{equation}
  и условия вида
  \begin{equation*}\label{eq:ode::tdmasys::bndcond}
    \begin{aligned}
      x &= a& \hat α \v y(a) &= \v β &\qquad \hat α \colon \R^s \to \R^p \\
      x &= b& \hat γ \v y(b) &= \v δ &\qquad \hat γ \colon \R^s \to \R^q \\
        &   &                &       & s &= p+q
    \end{aligned}
  \end{equation*}
  
  Если $y$~--- решение для которого выполнено условие выше, то $y$~--- решение
  граничной задачи.
\end{defn}

\begin{rem}
  Вообще, граничные условия бывают куда более общего вида, но мы их не рассматриваем.
  То, что у нас~--- это линейные распадающиеся граничные условия.

  А вот так выглядят нераспадающиеся: 
  \[
    \hat α\v y(a) + \hat γ \v y(b) = \v β, \qquad \hat α,\hat γ\colon \R^s\to\R^s
  \]
\end{rem}

Общее решение задачи Коши~\ref{eq:ode::tdmasys::ode} имеет вид
\[
  \v y(x) = \v y_0(x) + \sum_{j=1}^s c_j \v y_j(x)
\]
где как обычно $y_0$~--- решение неоднородной задачи Коши, а $\{y_{j}\}$~--- фундаментальная
система решений однородной.

\clause{Метод начальных данных} такой же в \ref{par:ode::bprobl}~--- находим
из граничных условий $\{c_j\}$ в общем решении.

Чтобы добыть решения задач Коши можно взять $\v y_j(a) = \v e_j$
(это единичный вектор с 1 на $j$ом месте), $\v y_0 (a) =0$

Можно снова уменьшить количество работы
% в этом месте было потеряно больше часа на поиск н.д в явном виде
\begin{enumerate}
  \item в качестве начальных данных для $y_0$~--- какое-нибудь решение системы $\hat α y = β$
  \item в качестве начальных данных для $y_j$, $j\in {p+1}\intrng {s}$~--- $q$ линейно независимых
    решений $\hat αy = 0$
  \item $y_j \equiv 0$, $j \in 1\intrng p$
\end{enumerate}

В итоге решение примет вид 
\[
  \v y(x) = \v y_0 (x) + \sum_{j=p+1}^{s} c_j \v y_j(x) 
\]

\plholdev{здесь снова этот понятный кусок про экспоненты и беды вычислений}\underdev

\clause{Метод прогонки,} в котором cнова зададим $\hat α, \v β$
\begin{equation}\label{eq:ode::tdmasys::tdma}
  \hat α(x) \, \v y(x) = \v β(x),  \qquad \hat α \colon [a;b]×\R^s \to \R^p 
\end{equation}
При таком условии $\forall\, x\holds y(x)\in M \subset \R^s$, $\dim M = s-p$ 
(предполагая что $\rk \hat α(x) = p$) 

Найдем уравнения на $\hat α(x), \v β(x)$
\[\bindvectors{y,β,f}\bindqoperators{α, A}% weeell, they just look simular
  \begin{aligned}
    α y &= β \\
    α y' +  α' y&=  β' \\
  \end{aligned} \so
  \begin{aligned}[t]
    &y' = Ay + f  \\
    &αAy  + αf + α'y  = β' \\
    \iff &(\underbrace{αA + α'})\,y - \underbrace{β'} = - αf 
  \end{aligned}
\]

Пусть $α_j$~--- строка $\hat α$.
Тогда мы получаем систему ОДУ первого порядка
\begin{equation}\label{eq:ode::tdmasys::direct}
  \begin{aligned}
    α_j' &= - \hat A^T \, α_j \\
    β_j' &= (α_j,\v f) \\
  \end{aligned}
\end{equation}

Посмотрим что происходит на правом конце
\begin{equation}\label{eq:ode::tdmasys::rightbndcond}
  \left\{\begin{aligned}
    \hat α(b) \, \v y(b) &= \v β(b) \\
    \hat γ \v y(b) &= \v δ \\
  \end{aligned}\right. 
\end{equation}
это просто линейная система порядка $s$ на $\v y(b)$, решаем и находим.

Сам метод выглядит так:
\begin{description}
  \item[прямая прогонка:] решаем прогоночные уравения\eqref{eq:ode::tdmasys::direct}
    с начальными данными $\hat α(a) = \hat α$, $\v β(a) = \v β$.
  \item[обратная прогонка:] уже зная $α(x)$, $β(x)$ решаем \eqref{eq:ode::tdmasys::tdma} c
    начальными данными $y(b)$, найденным из системы \eqref{eq:ode::tdmasys::rightbndcond}.
\end{description}

\begin{rem}\quest{}
  Метод с заменой $\hat A$ на сопряженную в прогоночных уравениях 
  уже пафосно называется методом \emph{сопряжённых систем}, но ничем кроме
  названия по сути не отличается.
\end{rem}

\begin{rem}
  Вообще, этот метод накладывает слишком жёсткие условия на $\hat α$, $\b β$.
  Например краевая задача из~\ref{par:ode::bprobl} им не решается. 
  Проблема возникает в том месте, где из $(\hat α\hat A + \hat α')\,\v y = 0$ выводится
  $\hat α\hat A + \hat α' =0$. Произвольностью $\v y$ мы вообще-то пользоваться не можем,
  так как на него есть условие $\hat α(x) \, \v y(x) = \v β(x)$.
\end{rem}

\begin{rem}
  У вышеописанного метода есть ещё пара недостатков:
  \begin{enumerate}
    \item $α_j' = -\hat A^T\, α_j$ отличается от исходной системы только отсутствием
      неоднородности, так от проблем связанных с потерей точности из-за собственных
      чисел разного знака в решениях задач Коши мы убежать не смогли.
    \item $\hat α \hat α^T$ может быть плохо обусловленной и ища $\v y(b)$ мы потеряем точность.
      \note{
      $\rk \hat α \hat α^T \geqslant 2\rk \hat α - s$ из теоремы Сильвестра о ранге,
    так что так в одну сторону вроде можно}
  \end{enumerate}

  Собственно, для того чтобы обойти эти проблемы и нужен \ref{par:ode::orthtdma}.
\end{rem}

\paragraph{Ортогональная прогонка}
\label{par:ode::orthtdma}

<<будем решать немного другую задачу>>

Заменим уравенение для $\hat α$ в методе выше.

\[\bindqoperators{α, A}
  α' = - αA \longrightarrow  α' = - α A + αA α^T \left(α α^T\right)^{-1} α
\]

Крокодил в формуле сверху~"--- ортогонанальная проекция $\hat α \hat A$ на $\hat α$,
а скалярное произведение имеет вид $(\hat α, \hat β) = \hat α \hat β^T$\note{
  на самом деле оно несимметрично. Нужно здесь понимать матрицу как набор векторов-строк.
  Тогда какой-то смысл есть.
}.
Так что по идее, раз мы проекцию на $\hat α$ вычли, $(\hat α',\hat α) = 0$.
Проверим:
\[\bindqoperators{α, A}
  α' α^T = -α A α^T + αA α^T \left(α α^T\right)^{-1} αα^T  = -α A α^T + αA α^T = 0
\]
Отсюда следует, что $\fder{}{x} \left( \hat α \hat α^T \right) = 0$, так что
матрица $\hat α \hat α^T$ постоянна на всём $[a;b]$

Получим уравнения на прогоночные коэффициенты
\[\bindvectors{y,β,f}\bindqoperators{α, A}% weeell, they just look simular
  \begin{aligned}[t]
    &αAy  + αf + α'y  = β' \\
    \iff &αAy + αf  -αAy + αAα^T \left(α α^T\right)^{-1} \underbrace{αy}_{β} = β'
  \end{aligned} 
\]
В итоге
\begin{equation}\label{equation:ode::orthtdma::tdma}
  \bindvectors{y,β,f}\bindqoperators{α, A}
  \begin{aligned}
    α' &=  - α A + αA α^T \left(α α^T\right)^{-1} α \\
    β' &= αf + αAα^T \left(α α^T\right)^{-1} β
  \end{aligned} 
\end{equation}

Разберёмся что делать с $\left(α α^T\right)^{-1}$. Не очень приятно каждый раз искать обратную 
матрицу.

На левой границе $\hat α(a) \v y(a) = \v β(a)$. Проведём процесс Грамма-Шмидта и 
ортогонализуем строчки $\hat α(a)$.
При этом заменили переменную в исходном уравении, соответственно поменялись 
$\hat A\to \hat B$, $\v f\to \v g$. Зато $\hat α(a)\, \hat α(a)^T = I$.
Так что прогоночные уравения принимают вид
\begin{equation}\label{equation:ode::orthtdma::tdma}
  \bindvectors{y,β,g}\bindqoperators{α, B}
  \begin{aligned}
    α' &=  - α B + αB α^T α \\
    β' &= αg + αBα^T β
  \end{aligned} 
\end{equation}

Поскольку $\hat α\hat α^T$ постоянна на $[a;b]$ (всюду $I$),
то проблем с её плохой обусловленностью в $x=b$ нет. Правое граничное условие
решится.

Судя по всему, это же условие исключает быстрый рост компонент $\hat α$.
Так что обе проблемы из замечания в конце предыдущего параграфа снимаются.
\quest\note{про это два слова в Крылове написано и больше нигде нет.}

Вышеописанный метод ещё называется методом Абрамова.


\paragraph{Разностный метод для краевой задачи 2 порядка}
\label{par:ode::findiff}




\end{document}


% vim:wrapmargin=3
