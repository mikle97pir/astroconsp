\documentclass{trlnotes}
\usepackage{trmath}
\addcompatiblelayout{commonplace}
\setlayout{commonplace}
\usepackage{trthm}
\usepackage{trsym} 
\usepackage{trphys}
% \input{mdefs}
\usepackage{silence}
\WarningFilter{latex}{Reference}
\graphicspath{{../../img/}}
\newtagform{roman}[\renewcommand{\theequation}{\Roman{equation}}]()
\begin{document}
\paragraph{Краевая задача для ОДУ 2 порядка и сведение к задаче Коши}
\label{par:ode::bprobl}
\begin{defn}\label{defn:ode::bprobl}
  Рассмотрим ОДУ 2 порядка
  \[
    y'' + p(x) y' + q(x) y = f(x) \qquad y \in C^2([a;b])
  \]
  и 3 варианта условий на $y$
  \begin{enumerate}[I]
    \item $y(a) = A, \quad y(b) = B$ \label{it:ode::bprobl::cond:i}
    \item $y'(a) = A, \quad y'(b) = B$ \label{it:ode::bprobl::cond::ii}
    \item $y'(a) = α y(a) + A, \quad y'(b) = βy(b) + B$ \label{it:ode::bprobl::cond::iii}
    \end{enumerate}
  
  Если $y$~--- решение для которого выполнено какое-то из условий выше, то $y$~--- решение
  граничной задачи.
\end{defn}

\begin{defn}[Однородная краевая задача]\label{defn:ode::bprobl::hom}
  Положим $f \equiv 0$ в \ref{defn:ode::bprobl}.
\end{defn}
\begin{defn}[Однородные граничные условия]\label{defn:ode::bprobl::hombnd}
  Положим $A = B = 0$ в граничных условиях в \ref{defn:ode::bprobl}
\end{defn}

\begin{thrm}[об альтернативе]\label{thrm:ode::bprobl::alt}
  Рассмотрим однородную граничную задачу с однородными граничными условиями.
  Пусть $y_H$~--- решение однородной задачи. 

  Тогда
  \begin{enumerate}
    \item $y_0 \equiv 0$~--- единственное решение однородной задачи \so неоднородная краевая 
      задача имеет единственное решение
    \item $y_0 \equiv 0$~--- неединственное решение однородной задачи \so неоднородная краевая 
      задача имеет бесконечно много или не имеет решений вовсе
  \end{enumerate}
\end{thrm}


\begin{prf}
  Рассмотреть решение неоднородной краевой в виде $y(x) = y_0(x) + c_1 y_1(x) + c_2 y_2(x)$
  и подставить граничные условия, а дальше все следует из линейной алгебры.
\end{prf}


Разберёмся как численно найти $y_0, y_1, y_2$, потребовавшиеся в предыдущем доказательстве.
Будем считать что $p,q,f$ определены на $I \ni [a;b]$, так что $y$ можно продолжить 
на $(a-ε;b+ε)$. 
\begin{enumerate}
  \item $y(a) = 0$, $y'(a) = 0$. Поскольку $0$ явно решение однородной задачи, то что мы
    найдем будет как раз частным решением неоднородной задачи (Коши!).
  \item $y_H(a) = 1$, $y'_H(a) = 0$ и решаем мы тут однородную задачу (Коши!). Будем считать то что
    нашлось $y_1$
  \item $y_H(a) = 0$, $y'_H(a) = 1$. Скажем что это $y_2$. Здесь важно заметить про линейную
    независимость $y_1$ и $y_2$. Найдем определитель Вронского в точке $a$
    \[
      W = \begin{vmatrix}
        y_1(a) & y_2(a) \\
        y_1'(a) & y_2'(a) 
      \end{vmatrix} = 
      \begin{vmatrix}
        1 & 0 \\ 
        0 & 1 \\
      \end{vmatrix} = 1 \neq 0
    \]
    А тогда он нигде не ноль. А значит $y_1$ и $y_2$ линейно независимы.
\end{enumerate}

Всё это называется \emph{методом начальных данных} для решения краевой задачи.

В рассуждении выше можно было бы взять другие начальные данные дабы
упростить себе жизнь. Ведь никто не запрещает запихать, например, кусок $y_2$ в $y_0$
(если мы уже знаем правильное $c_2$). Нам просто были нужны какие-то линейно независимые
решения однородной задачи.

Рассмотрим граничную задачу в форме \ref{it:ode::bprobl::cond::iii}
\begin{enumerate}
  \item $y(a) = 0$, $y'(a) = A$, нашли  $y_0$.
  \item $y_H(a) = 1$, $y'_H(a) = α$, нашли $y_1$.
  \item $y_H(a) = 0$, $y'_H(a) = 0$. Мы просто решили что $y_2 \equiv 0$. Эту ЗК мы даже
    не решаем, а сразу знаем ответ.
\end{enumerate}
При таком раскладе $y(x) = y_0(x) + c_1 y_1(x)$. 
Проверим левое граничное условие 
\[
  \begin{split}
    y(a) &= y_0(a) + c_1\, y_1(a) = 0 + c_1 \, 1 = c_1 \\
    y'(a) &= y_0'(a) + c_1\, y_1'(a) = A + c_1 \, α = A + α\ y(a)
  \end{split}
\]
Как видно, всё получилось.

В случае \ref{it:ode::bprobl::cond:i} можно сделать так:
\begin{enumerate}
  \item $y(a) = A$, $y'(a) = 0$, нашли $y_0$.
  \item $y_H(a) = 0$, $y_H'(a) = 1$, нашли $y_1$.
\end{enumerate}
Как видно, свободы в выборе $c_1$ хватает чтобы разобраться с правой границей.

\begin{exmp}
  $y'' - q^2 y =0$, $y(0) = 1$, $y(b) = 1$

  \underdev, а он важный вообще-то, из него необходимость метода прогонки следует.
\end{exmp}

\paragraph{Метод дифференциальной прогонки}
\label{par:ode::difftdma}

Здесь будем решать краевую задачу с граничными условиями в форме \ref{it:ode::bprobl::cond::iii}.

Рассмотрим $α(x)$, $β(x) \that$ (прогоночные коэффициенты)
\begin{equation} \label{eq:ode::difftdma::tmda}
  y'(x) = α(x) \, y(x) + β(x)
\end{equation}
Такая форма напрашивается при вспоминании трюка, который мы делали в прошлом параграфе.
Там как раз $y'(a) = y_0(a) + c_1\, y_1(a)$, а $c_1 = y(a)$.
Здесь мы пока вводим прогоночные коэффициенты формально, а существование покажем конструктивно.

Найдем уравнения на $α, β$
\[
  \begin{aligned}
    y'  &= α y + β \\
    y'' &= α y' + α'y + β'
  \end{aligned} \so
  \begin{aligned}[t]
    &y'' + py' + qy = f \\
    \iff &αy' + α'y + β' + p (αy + β) + qy = f \\
    \iff &y\,(\underbrace{α^2 + α' + p α + q}_{0}) + \underbrace{α β + β' + pβ}_f = f 
  \end{aligned}
\]
В итоге получаем систему ОДУ первого порядка
\begin{equation}\label{eq:ode::difftdma::direct}
  \begin{aligned}
    α' &= - α^2 - p α - q \\
    β' &= f - pβ - αβ \\
  \end{aligned}
\end{equation}

Посмотрим что происходит на правом конце\footnote{а что делать если $α(b)=β$ неясно}
\[
  \begin{aligned}
    y'(b) &= α(b) y(b) + β(b) \\
    y'(b) &= β y(b) + B \\
  \end{aligned} \so y(b) = \frac{B- β(b)}{α(b) - β} 
\]
Сам метод выглядит так:
\begin{description}
  \item[прямая прогонка:] решаем систему \eqref{eq:ode::difftdma::direct} с начальными данными
    $α(a) = α$, $β(a) = A$.
  \item[обратная прогонка:] уже зная $α(x)$, $β(x)$ решаем \eqref{eq:ode::difftdma::tmda} c
    начальными данными $y(b) = \frac{B- β(b)}{α(b) - β}$.
\end{description}

\begin{rem}
  Рассмотрим однородную задачу с однородными граничными условиями. 
  Тогда \eqref{eq:ode::difftdma::tmda} переходит в $y'(x) = α(x) \, y(x)$.
  Если при этом $\exists\, c\in (a;b) \that y(c) = 0 \land y'(c) \neq 0$, то $α(c)$ не
  существует. Так что, как видно, не всякое решение краевой задачи можно найти методом
  прогонки.
\end{rem}

\paragraph{Метод прогонки для систем ОДУ}
\label{par:ode::tdmasys}

\begin{defn}\label{defn:ode::tdmasys::bprobl}
  Рассмотрим ОДУ
  \begin{equation}\label{eq:ode::tdmasys::ode}
    \v y' = \hat A(x) \,\v y + \v f(x) \qquad \v y \in C^2([a;b]), \quad y \colon [a;b]\to \R^s
  \end{equation}
  и условия вида
  \begin{equation*}\label{eq:ode::tdmasys::bndcond}
    \begin{aligned}
      x &= a& \hat α \v y(a) &= \v β &\qquad \hat α \colon \R^s \to \R^p \\
      x &= b& \hat γ \v y(b) &= \v δ &\qquad \hat γ \colon \R^s \to \R^q \\
        &   &                &       & s &= p+q
    \end{aligned}
  \end{equation*}
  
  Если $y$~--- решение для которого выполнено условие выше, то $y$~--- решение
  граничной задачи.
\end{defn}

\begin{rem}
  Вообще, граничные условия бывают куда более общего вида, но мы их не рассматриваем.
  То, что у нас~--- это линейные распадающиеся граничные условия.

  А вот так выглядят нераспадающиеся: 
  \[
    \hat α\v y(a) + \hat γ \v y(b) = \v β, \qquad \hat α,\hat γ\colon \R^s\to\R^s
  \]
\end{rem}

Общее решение задачи Коши~\ref{eq:ode::tdmasys::ode} имеет вид
\[
  \v y(x) = \v y_0(x) + \sum_{j=1}^s c_j \v y_j(x)
\]
где как обычно $y_0$~--- решение неоднородной задачи Коши, а $\{y_{j}\}$~--- фундаментальная
система решений однородной.

\clause{Метод начальных данных} такой же в \ref{par:ode::bprobl}~--- находим
из граничных условий $\{c_j\}$ в общем решении.

Чтобы добыть решения задач Коши можно взять $\v y_j(a) = \v e_j$
(это единичный вектор с 1 на $j$ом месте), $\v y_0 (a) =0$

Можно снова уменьшить количество работы
% в этом месте было потеряно больше часа на поиск н.д в явном виде
\begin{enumerate}
  \item в качестве начальных данных для $y_0$~--- какое-нибудь решение системы $\hat α y = β$
  \item в качестве начальных данных для $y_j$, $j\in {p+1}\intrng {s}$~--- $q$ линейно независимых
    решений $\hat αy = 0$
  \item $y_j \equiv 0$, $j \in 1\intrng p$
\end{enumerate}

В итоге решение примет вид 
\[
  \v y(x) = \v y_0 (x) + \sum_{j=p+1}^{s} c_j \v y_j(x) 
\]

\plholdev{здесь снова этот понятный кусок про экспоненты и беды вычислений}\underdev

\clause{Метод прогонки,} в котором cнова зададим $\hat α, \v β$
\begin{equation}\label{eq:ode::tdmasys::tdma}
  \hat α(x) \, \v y(x) = \v β(x),  \qquad \hat α \colon [a;b]×\R^s \to \R^p 
\end{equation}
При таком условии $\forall\, x\holds y(x)\in M \subset \R^s$, $\dim M = s-p$ 
(предполагая что $\rk \hat α(x) = p$) 

Найдем уравнения на $\hat α(x), \v β(x)$
\[\bindvectors{y,β,f}\bindqoperators{α, A}% weeell, they just look simular
  \begin{aligned}
    α y &= β \\
    α y' +  α' y&=  β' \\
  \end{aligned} \so
  \begin{aligned}[t]
    &y' = Ay + f  \\
    &αAy  + αf + α'y  = β' \\
    \iff &(\underbrace{αA + α'})\,y - \underbrace{β'} = - αf 
  \end{aligned}
\]

Пусть $α_j$~--- строка $\hat α$.
Тогда мы получаем систему ОДУ первого порядка
\begin{equation}\label{eq:ode::tdmasys::direct}
  \begin{aligned}
    α_j' &= - \hat A^T \, α_j \\
    β_j' &= (α_j,\v f) \\
  \end{aligned}
\end{equation}

Посмотрим что происходит на правом конце
\begin{equation}\label{eq:ode::tdmasys::rightbndcond}
  \left\{\begin{aligned}
    \hat α(b) \, \v y(b) &= \v β(b) \\
    \hat γ \v y(b) &= \v δ \\
  \end{aligned}\right. 
\end{equation}
это просто линейная система порядка $s$ на $\v y(b)$, решаем и находим.

Сам метод выглядит так:
\begin{description}
  \item[прямая прогонка:] решаем прогоночные уравения\eqref{eq:ode::tdmasys::direct}
    с начальными данными $\hat α(a) = \hat α$, $\v β(a) = \v β$.
  \item[обратная прогонка:] уже зная $α(x)$, $β(x)$ решаем \eqref{eq:ode::tdmasys::tdma} c
    начальными данными $y(b)$, найденным из системы \eqref{eq:ode::tdmasys::rightbndcond}.
\end{description}

\begin{rem}\quest{}
  Метод с заменой $\hat A$ на сопряженную в прогоночных уравениях 
  уже пафосно называется методом \emph{сопряжённых систем}, но ничем кроме
  названия по сути не отличается.
\end{rem}

\begin{rem}
  Вообще, этот метод накладывает слишком жёсткие условия на $\hat α$, $\b β$.
  Например краевая задача из~\ref{par:ode::bprobl} им не решается. 
  Проблема возникает в том месте, где из $(\hat α\hat A + \hat α')\,\v y = 0$ выводится
  $\hat α\hat A + \hat α' =0$. Произвольностью $\v y$ мы вообще-то пользоваться не можем,
  так как на него есть условие $\hat α(x) \, \v y(x) = \v β(x)$.
\end{rem}

\begin{rem}
  У вышеописанного метода есть ещё пара недостатков:
  \begin{enumerate}
    \item $α_j' = -\hat A^T\, α_j$ отличается от исходной системы только отсутствием
      неоднородности, так от проблем связанных с потерей точности из-за собственных
      чисел разного знака в решениях задач Коши мы убежать не смогли.
    \item $\hat α \hat α^T$ может быть плохо обусловленной и ища $\v y(b)$ мы потеряем точность.
      \note{
      $\rk \hat α \hat α^T \geqslant 2\rk \hat α - s$ из теоремы Сильвестра о ранге,
    так что так в одну сторону вроде можно}
  \end{enumerate}

  Собственно, для того чтобы обойти эти проблемы и нужен \ref{par:ode::orthtdma}.
\end{rem}

\paragraph{Ортогональная прогонка}
\label{par:ode::orthtdma}

<<будем решать немного другую задачу>>

Заменим уравенение для $\hat α$ в методе выше.

\[\bindqoperators{α, A}
  α' = - αA \longrightarrow  α' = - α A + αA α^T \left(α α^T\right)^{-1} α
\]

Крокодил в формуле сверху~"--- ортогонанальная проекция $\hat α \hat A$ на $\hat α$,
а скалярное произведение имеет вид $(\hat α, \hat β) = \hat α \hat β^T$\note{
  на самом деле оно несимметрично. Нужно здесь понимать матрицу как набор векторов-строк.
  Тогда какой-то смысл есть.
}.
Так что по идее, раз мы проекцию на $\hat α$ вычли, $(\hat α',\hat α) = 0$.
Проверим:
\[\bindqoperators{α, A}
  α' α^T = -α A α^T + αA α^T \left(α α^T\right)^{-1} αα^T  = -α A α^T + αA α^T = 0
\]
Отсюда следует, что $\fder{}{x} \left( \hat α \hat α^T \right) = 0$, так что
матрица $\hat α \hat α^T$ постоянна на всём $[a;b]$

Получим уравнения на прогоночные коэффициенты
\[\bindvectors{y,β,f}\bindqoperators{α, A}% weeell, they just look simular
  \begin{aligned}[t]
    &αAy  + αf + α'y  = β' \\
    \iff &αAy + αf  -αAy + αAα^T \left(α α^T\right)^{-1} \underbrace{αy}_{β} = β'
  \end{aligned} 
\]
В итоге
\begin{equation}\label{eq:ode::orthtdma::tdma}
  \bindvectors{y,β,f}\bindqoperators{α, A}
  \begin{aligned}
    α' &=  - α A + αA α^T \left(α α^T\right)^{-1} α \\
    β' &= αf + αAα^T \left(α α^T\right)^{-1} β
  \end{aligned} 
\end{equation}

Разберёмся что делать с $\left(α α^T\right)^{-1}$. Не очень приятно каждый раз искать обратную 
матрицу.

На левой границе $\hat α(a) \v y(a) = \v β(a)$. Проведём процесс Грамма-Шмидта и 
ортогонализуем строчки $\hat α(a)$.
При этом заменили переменную в исходном уравении, соответственно поменялись 
$\hat A\to \hat B$, $\v f\to \v g$. Зато $\hat α(a)\, \hat α(a)^T = I$.
Так что прогоночные уравения принимают вид
\begin{equation}\label{eq:ode::orthtdma::orthtdma}
  \bindvectors{y,β,g}\bindqoperators{α, B}
  \begin{aligned}
    α' &=  - α B + αB α^T α \\
    β' &= αg + αBα^T β
  \end{aligned} 
\end{equation}

Поскольку $\hat α\hat α^T$ постоянна на $[a;b]$ (всюду $I$),
то проблем с её плохой обусловленностью в $x=b$ нет. Правое граничное условие
решится.

Судя по всему, это же условие исключает быстрый рост компонент $\hat α$.
Так что обе проблемы из замечания в конце предыдущего параграфа снимаются.
\quest\note{про это два слова в Крылове написано и больше нигде нет.}

Вышеописанный метод ещё называется методом Абрамова.


\paragraph{Разностный метод для краевой задачи 2 порядка}
\label{par:ode::findiff}
\begin{aux}
  \textit{Предупреждение:}
  в силу повышенной техничности этого параграфа он написан в соответствующем стиле.
  Что поделать. Приятного прочтения.
\end{aux}

Решать краевую задачу для дифференциального уравения второго порядка
\begin{equation}
  y'' + p(x) y' + q(x) y = f(x) \qquad y \in C^2([a;b]) \label{eq:ode::findiff::ode}
\end{equation}

\clause{Алгоритм}
\begin{defn}[Метод разностной прогонки]\label{defn:ode::findiff::alg}
  Пусть задано дифференциальное уравнение с граничными условиями.
  Методом разностной прогонки называет следующий алгоритм:
  \begin{enumerate}
    \item Выбор сетки: узлы, шаг (если она равномерная)
    \item Построение сеточных уравений
      \begin{enumerate}
        \item Диффур в узлах сетки
        \item Все производные через конечные разности
      \end{enumerate}
    \item Решение получившейся линейной системы
  \end{enumerate}
\end{defn}

Будем дальше всюду считать, что решение задано на $[a;b]$
\[
  \text{$n$ узлов}\qquad h = \frac{b-a}{n} \qquad x_k = a + kh
\]
\clause{Формулы численного дифференцирования} 
Здесь $M_n = \max \abs{y^{(m)}(x)}$
\begin{align}
  \label{eq:ode::findiff::simpforward}
  y'(x) &= \frac{y(x+h) -y (x)}{h} + R & \abs{R} &\leqslant \tfrac{hM_2}{2} \\
  \label{eq:ode::findiff::simpbackward}
  y'(x) &= \frac{y(x) - y (x-h)}{h} + R & \abs{R} &\leqslant \tfrac{hM_2}{2} \\
  \label{eq:ode::findiff::threepointforward}
  y'(x) &= \frac{-y(x+2h) + 4y (x+h) - 3y(x)}{2h} + R & \abs{R} &\leqslant \tfrac{h^2M_3}{3} \\
  \label{eq:ode::findiff::threepointbackward}
  y'(x) &= \frac{3y(x) - 4y (x-h) + y(x-2h)}{2h} + R & \abs{R} &\leqslant \tfrac{h^2M_3}{3} \\
  \label{eq:ode::findiff::simmetric}
  y'(x) &= \frac{y(x+h) - y (x-h)}{2h} + R & \abs{R} &\leqslant \tfrac{h^2M_3}{6} \\
  \label{eq:ode::findiff::simmetricsecondorder}
  y''(x) &= \frac{y(x+h) - 2y (x) + y(x-h)}{h^2} + R & \abs{R} &\leqslant \tfrac{h^2M_4}{12}
\end{align}
Cхемы \ref{eq:ode::findiff::simpforward} и \ref{eq:ode::findiff::simpbackward} называются 
простейшими.

\clause{Разностное уравнение}

\begin{equation*}
  \frac{y(x_{k+1}) - 2y(x_k) + y(x_{k-1})}{h^2} + R_1 
  + p(x_k) \, \frac{y(x_{k+1}) - y(x_{k-1})}{2h} + p(x_k)\,R_2 
  + q(x_k) \, y(x_k) = f(x_k)
\end{equation*}

Можно заметить, что $R_1 + p(x_k)\, R_2 = O(h^2)$.
Так что можно вместо $y(x_k)$ получить приближённое решение $y_k$
(по сути, решение уже совсем другой задачи). Попутно, обозначим
\[
  p(x_k) = p_k,\qquad q(x_k) = q_k, \qquad f(x_k) = f_k.
\]
Получится
\begin{equation}\label{eq:ode::findiff::diffeq}
  \frac{y_{k+1} - 2y_k + y_{k-1}}{h^2}
  + p_k \, \frac{y_{k+1} - y_{k-1}}{2h} 
  + q_k \, y_k = f_k
\end{equation}

\clause{Граничные условия} будут рассматриваться \ref{it:ode::bprobl::cond::iii} типа,
но вообще это неважно. Всё равно раскрывать не будем.

\begin{enumerate}
  \item \emph{Трёхточечная односторонняя аппроксимация}
      \begin{equation*}
        y'(x) = \frac{-y(x+2h) + 4y(x+h) - 3 y(x)}{2h} + O(h^2)
      \end{equation*}

      Запишем это выражение для границ:
      \begin{alignat*}{3}
        y'(a) &= \frac{-y(a+2h) + 4y(a+h) - 3 y(a)}{2h} + O(h^2) 
              &\quad&\to\quad &
        αy_0 + A &= \frac{-y_2 + 4 y_1 - 3y_0}{2h}\\
        y'(b) &= \frac{3y(b) - 4y(b-h) + y(b-2h)}{2h} + O(h^2) 
              &\quad&\to\quad &
        βy_n + B &= \frac{3y_n - 4 y_{n-1} + y_{n-2}}{2h}
      \end{alignat*}
    \item \emph{Метод фиктивных узлов}
      \begin{enumerate}
        \item Введём $y_{-1} = y(a-h)$, $y_{n+1} = y(b+h)$
          \begin{equation*}
            y'(x) = \frac{y(x+h) - y(x-h)}{2h} + O(h^2)
          \end{equation*}

          Запишем это выражение для границ:
          \begin{alignat*}{3}
            y'(a) &= \frac{y(a+h) - y(a-h)}{2h} + O(h^2) 
                  &\quad&\to\quad &
            αy_0 + A &= \frac{y_1 - y_{-1}}{2h}\\
            y'(b) &= \frac{y(b+h) - y(b-h)}{2h} + O(h^2) 
                  &\quad&\to\quad &
            βy_n + B &= \frac{y_{n+1} - y_{n-1}}{2h}
          \end{alignat*}
          Как правило, решение можно продолжить с отрезка на интервал побольше, подберём
          $h \that y(a-h) \in I \land y(b+h) \in I$. Так что такой метод имеет смысл.
        \item Сдвинем сетку на $\lfrac h2$, $x_0 = a-\lfrac h2$, $x_{n+1} = b+\lfrac h2$
          \[
            x_k = a- \lfrac h2 + kh \qquad k = 0,1 \intrng n+1
          \]
          Значения в узлах сетки при этом придётся вводить с помощью интерполяции
          \[
            y(a) = \frac{y(a-\lfrac{h}2) + y(a+\lfrac{h}2)}{2}
          \]
          Сами выражения для производной имеют вид
          \begin{equation*}
            y'(x) = \frac{y(x+\lfrac h2) - y(x-\lfrac h2)}{h} + O(h^2)
          \end{equation*}

          Запишем это выражение для границ:
          \begin{alignat*}{3}
            y'(a) &= \frac{y(a+\lfrac{h}2) - y(a-\frac{h}2)}{h} + O(h^2) 
                  &\quad&\to\quad &
            α\, \frac{y_0 + y_1}{2} + A &= \frac{y_1 - y_{0}}{h}\\
            y'(b) &= \frac{y(b+\lfrac h2) - y(b-\lfrac h2)}{h} + O(h^2) 
                  &\quad&\to\quad &
            β\, \frac{y_{n+1} - y_n}{2} + B &= \frac{y_{n+1} - y_{n-1}}{2h}
          \end{alignat*}

          Такой подход не очень удобен если нужны значения в узлах. Придётся уменьшать шаг
          в $2$ раза.
      \end{enumerate}
    \item \emph{Использование ДУ для исключения главного члена простейшей формулы}\par
        \begin{equation*}
          y'(x) = \frac{y(x+h) - y(x)}{h} + R, \quad R = O(h)
        \end{equation*}
        Теперь запишем разложение в ряд Тейлора:
        \begin{equation*}
          y(x+h) = y(x) + h y'(x) + \frac{h^2}{2}y''(x) + O(h^3) 
          \iff y'(x)  = \frac{y(x+h) - y(a)}{h}  - \frac h2 y''(x) + O(h^2)
        \end{equation*}
        Из исходного уравнения \eqref{eq:ode::tdmasys::ode} подстановкой простейшей формулы получаем
        \begin{align*}
          y''(x) &= -\bigl(p(x) y'(x) + q(x) y(x) \bigr) + f(x)  
          = -\left(p(x) \,\tfrac{y(x+h) -y(x)}{h} + p(x) O(h) + q(x) y(x) \right) + f(x)
          \notag \\
          \so 
          -\tfrac{h}{2} y''(x) &= \tfrac{p(x)}{2} \Bigl(y(x+h) - y(x)\Bigr) + 
          \tfrac{h}{2} \Bigl(q(x)y(x) - f(x)\Bigr) + O(h^2)
        \end{align*}
        
        Оценка производной на краю
        \begin{align*}
          y'(a) &= \frac{y(a+h) - y(a)}{h} + \frac{p(a)}{2} \biggl(y(a+h) - y(a)\biggr) + 
          \frac{h}{2} \biggl(q(a) y(a) - f(a)\biggr) + O(h^2)\\
          y'(b) &= \frac{y(b) - y(b-h)}{h} - \frac{p(b)}{2} \biggl(y(b) - y(b-h)\biggr) - 
          \frac{h}{2}\,\biggl(q(b) y(b) - f(b)\biggr) + O(h^2)
        \end{align*}

        На сетке оно имеет вид
        \begin{equation*}
          \begin{split}
            α y_0 + A &= \frac{y_1 - y_{0}}{h} + \frac{p_0}{2} \biggl(y_1 - y_{0}\biggr)
            + \frac{h}{2}\,\biggl(q_0 y_0 - f_0\biggr) \\
            β y_n + B &= \frac{y_n - y_{n-1}}{h} - \frac{p_n}{2} \biggl(y_n - y_{n-1}\biggr)
            - \frac{h}{2}\,\biggl(q_n y_n - f_n\biggr) \\
            \end{split}
        \end{equation*}
\end{enumerate}

\clause{Составление системы линейных уравнений}
\begin{equation}\label{eq:ode::findiff::tdma}
  \begin{aligned}
    c_0 y_1     &- b_0 y_0                  &&=& &d_0 \\
    c_k y_{k+1} &- b_k y_k+ y_{k-1} a_k     &&=& &d_k,\quad k= 1\intrng n-1 \\
                &- b_n y_n + a_n y_{n-1}    &&=& &d_n 
  \end{aligned}
\end{equation}
Из разностного уравнения \eqref{eq:ode::findiff::diffeq} можно найти $a_k, c_k, b_k, d_k$
\[
  \begin{aligned}
    a_k &= 1- \tfrac{h}2 \, p_k &
    b_k &= 1- h^2 \, q_k &
    c_k &= 1+ \tfrac{h}2 \, p_k &
    d_k &= {h}^2 \, f_k 
  \end{aligned}
\]

Явные выражения для $a_0, b_0, c_0, d_0$ и $a_n, b_n, c_n, d_n$
зависят от способа учета граничных условий. Разве что $a_0 = 0\land c_0 = 0$.
Оставим остальные читателям из Беларуси в качестве упражнения.

\paragraph{Метод разностной прогонки}
\label{par:ode::fintdma}
Вспомним систему линейную систему~\ref{eq:ode::findiff::tdma}.
Её матрица, как видно чуть ниже, трёхдиагональная.
\[
  \begin{pmatrix}
    -b_0   & c_0    &         &          & 0       \\
    a_1    & -b_1   & c_1     &          &         \\
           & \ddots & \ddots  & \ddots             \\
           &        & a_{n-1} & -b_{n-1} & c_{n-1} \\
    0      &        &         & a_n      & -b_n    \\
  \end{pmatrix}
\]
Такие СЛУ можно решать не за $O(n^3)$, а за $O(n)$. Опишем, как именно.


Преобразум систему: уберём поддиагональ, на самой диагонали оставим всюду 1.
Тогда можно написать прогоночное соотношение, очень похожее на такое же для 
дифференциальной прогонки (в \ref{par:ode::difftdma}). 
\begin{equation}\label{eq:ode::fintdma::direct}
  y_k = α_k y_{k+1} + β_k
\end{equation}

% спёр из своего отчёта: там слишком хорошо, мне лучше не сделать
Свяжем $α, β$ с $a, b, c, d$.
\[
  \left\{
  \begin{aligned}
    &y_{k-1} = α_{k-1} y_k + β_{k-1} \\
    &a_k y_{k-1} - b_k y_k + c_k y_{k+1} = d_k
  \end{aligned}\right. 
  \so
  \begin{aligned}[t]
         &a_k α_{k-1} y_{k} + a_k β_{k-1} - b_k y_k + c_k y_{k+1} = d_k \\
    \iff &y_k = \frac{c_k}{b_k - a_k α_{k-1}}y_{k+1} + \frac{a_k β_{k-1} - d_k}{b_k - a_k α_{k-1}}
  \end{aligned}
\]

Отсюда получаются удобные рекурсивные соотношения для $α_k, β_k$
\begin{equation}\label{eq:ode::fintdma::tdmaeq}
  α_k = \frac{c_k}{b_k - a_k α_{k-1}}; \qquad β_k = \frac{a_k β_{k-1} - d_k}{b_k - a_k α_{k-1}}
\end{equation}
Начальные значения $α_k, β_k$ легко определяются из линейной системы на
$a_k, b_k, c_k, d_k$ \eqref{eq:ode::findiff::tdma}.

Итак, алгоритм, следующий
\begin{description}
  \item[прямая прогонка:] решаем прогоночные уравения~\eqref{eq:ode::fintdma::tdmaeq}
    с начальными данными $α_0 = \frac{c_0}{b_0}$, $β_0 = -\frac{d_0}{b_0}$.
  \item[обратная прогонка:] уже зная $α_k$, $β_k$ решаем прогоночное соотношение 
    \eqref{eq:ode::fintdma::direct} c
    начальными данными $y_n = β_n$ ($c_n = 0 \so α_n = 0$).
\end{description}

Как видно, что прямая, что обратная прогонка имеют асимптотику $O(n)$, что не может не
радовать.
Теперь подумаем над корректностью метода.
\paragraph{Лемма об оценке для системы разностных уравений}
\label{par:ode::diffeqest}

\begin{lem}[Достаточное условие]\label{prop:ode::diffeqest::suff}
  Пусть $\forall k\holds a_k, c_k > 0$ ($c_n, a_0 = 0$), и СЛУ имеет
  диагональное преобладание: $b_k \geqslant a_k + c_k$.

  Тогда прогоночные уравнения \ref{eq:ode::fintdma::tdmaeq} разрешимы
\end{lem}
\begin{prf}
  Проблемы у нас возникнут только если знаменатели обратятся в $0$.
  Учитывая диагональное преобладание, это эквивалентно $α_{k-1} < 1$.
  
  \gprov $0 < α_{k-1} \leqslant 1$ (по индукции)
  \begin{description}
    \item[база:] $α_0 = \frac{c_0}{b_0}$, $b_0 \geqslant c_0 > 0$, $c_0 \leqslant b_0$.
      Кажется, все верно.\note{здесь бы и хотелось сразу $α_0 < 1$, да $a_0 = 0$, 
      так что неравенство $c_0 \leqslant b_0$ нестрогое}
    \item[переход:] Знаем что $α_{k-1} \leqslant 1$. 
      Так что из условий теоремы
      \[
        b_k - α_{k-1} a_k \geqslant b_k - a_k \geqslant c_k > 0 \so 
        0< α_k = \frac{c_k}{b_k - a_k α_{k-1}} \leqslant 1
      \]
      Попутно, верно ещё два уточнения:
      \begin{enumerate}
        \item Если $α_{k-1} < 1$, то $α_k < 1$, поскольку $b_k - α_{k-1} a_k > b_k - a_k$
        \item $α_k < 1$ при $k\in 1\intrng n-1$, 
          поскольку неравенство $b_k -a_k > c_k$ строгое при таких $k$.
      \end{enumerate}
  \end{description}
  Таким образом, все $α_k$ определены.
\end{prf}

Посмотрим, какие условия это накладывает на уравнение.
Вспомним выражения для $a_k, \ldots$
\[
  \begin{aligned}
    a_k &= 1- \tfrac{h}2 \, p_k &
    b_k &= 1- h^2 \, q_k &
    c_k &= 1+ \tfrac{h}2 \, p_k &
    d_k &= {h}^2 \, f_k 
  \end{aligned}
\]
Отсюда
\[
  \begin{aligned}
    a_k &> 0 &&\Leftarrow& h &< \tfrac{2}{\max \abs{p_k}}\\
    c_k &> 0 &&\Leftarrow& h &< \tfrac{2}{\max \abs{p_k}} \\
    b_k &\geqslant c_k + a_k &&\iff& q_k &\leqslant 0 
  \end{aligned}
\]

\plholdev{подумать про граничные условия}

\end{document}


% vim:wrapmargin=3
